{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "949fd075-55f4-4826-abd6-93e34c264c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT THE REQUIRED LIBRARIES\n",
    "\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Output,\n",
    "                        Model,\n",
    "                        Metrics,\n",
    "                        Markdown,\n",
    "                        HTML,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import aiplatform as vertex_\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00ebb14-3e22-4250-b692-48fac5eca458",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "REGION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d56f06d-5732-4595-99a9-ab99a1f1c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME=\"gs://\"+\"osn-smartcapex-data-uploaded-sbx/staging\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/smartcapex_pipeline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd6f800-60b3-4dc1-b0bd-4a06e4c29530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom base image created using docker\n",
    "\n",
    "IMAGE_NAME = \"smartcapex-pipeline\"\n",
    "BASE_IMAGE = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/osn-smartcapex-404-sbx/{IMAGE_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed920c77-0e5d-487a-8395-d7a81bc06160",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e2cdc-3e5a-42ae-a596-5cdafc296e7c",
   "metadata": {},
   "source": [
    "Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb11388e-adac-479f-8385-2e02e4be86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    output_component_file=\"components/get_data.yaml\"\n",
    ")\n",
    "\n",
    "def get_data(\n",
    "    project_id: str, \n",
    "    dataset_src: str,\n",
    "    table_id: str,\n",
    "    dataset_raw: Output[Dataset],\n",
    "):\n",
    "    \"\"\"\n",
    "    Get data from BigQuery\n",
    "    \"\"\"\n",
    "    \n",
    "    from google.cloud import bigquery \n",
    "    import pandas as pd\n",
    "    \n",
    "    client = bigquery.Client(project=project_id)\n",
    "    query = f\"select * from `{project_id}.{dataset_src}.{table_id}`\"\n",
    "    data = client.query(query = query).to_dataframe()\n",
    "    data.to_csv(dataset_raw.path, index=False)\n",
    "    print(f\"Data successfully read from BigQuery table : {project_id}.{dataset_src}.{table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f06536-69ce-4fa7-8eb9-12b7a2077e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    output_component_file=\"components/preprocessing.yaml\"\n",
    ")\n",
    "\n",
    "def preprocess_data(\n",
    "    raw_sites_df: Input[Dataset],\n",
    "    raw_oss_2g_df: Input[Dataset],\n",
    "    raw_oss_3g_df: Input[Dataset],\n",
    "    raw_oss_4g_df: Input[Dataset],\n",
    "    raw_oss_rtx_df: Input[Dataset],\n",
    "    dataset_sites_preprocessed: Output[Dataset],\n",
    "    dataset_oss_preprocessed: Output[Dataset],\n",
    "):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from src.d02_preprocessing.process_sites import sites_preprocessing\n",
    "    from src.d02_preprocessing.process_oss import preprocessing_oss_counter_weekly\n",
    "   \n",
    "    raw_sites_df = pd.read_csv(raw_sites_df.path)\n",
    "    raw_oss_2g_df = pd.read_csv(raw_oss_2g_df.path)\n",
    "    raw_oss_3g_df = pd.read_csv(raw_oss_3g_df.path)\n",
    "    raw_oss_4g_df = pd.read_csv(raw_oss_4g_df.path)\n",
    "    raw_oss_rtx_df = pd.read_csv(raw_oss_rtx_df.path)\n",
    "    \n",
    "    \n",
    "    sites_preprocessed = sites_preprocessing(raw_sites_df)\n",
    "    oss_preprocessed = preprocessing_oss_counter_weekly(sites_preprocessed,raw_oss_2g_df,raw_oss_3g_df,raw_oss_4g_df,raw_oss_rtx_df)\n",
    "    sites_preprocessed.to_csv(dataset_sites_preprocessed.path, index=False)\n",
    "    oss_preprocessed.to_csv(dataset_oss_preprocessed.path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93bcb7d2-085a-4229-93ec-f15bbca27cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    ")\n",
    "def compute_sites_distances(\n",
    "    dataset_sites_preprocessed: Input[Dataset],\n",
    "    df_distance: Output[Dataset],\n",
    "\n",
    "):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from src.d03_capacity.technical_modules.cluster_selection import compute_distance_between_sites\n",
    "   \n",
    "    df_sites = pd.read_csv(dataset_sites_preprocessed.path)\n",
    "    distance = compute_distance_between_sites(df_sites)\n",
    "    \n",
    "    distance.to_csv(df_distance.path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494888b8-2d6a-47e3-8470-0fca5f12490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    output_component_file=\"components/save_to_bigquery.yaml\"\n",
    ")\n",
    "\n",
    "def save_to_bigquery(\n",
    "    dataset_preprocessed: Input[Dataset],\n",
    "    project_id: str,\n",
    "    dataset_id: str,\n",
    "    table_output: str\n",
    "):\n",
    "    import pandas as pd\n",
    "    import pandas_gbq\n",
    "    \n",
    "    dataset_preprocessed = pd.read_csv(dataset_preprocessed.path)\n",
    "    \n",
    "    pandas_gbq.to_gbq(dataset_preprocessed, f'{project_id}.{dataset_id}.{table_output}', project_id=project_id, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "617c8ae1-6792-4423-8093-d1be9647f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    output_component_file=\"components/traffic_forcasting.yaml\"\n",
    ")\n",
    "\n",
    "def traffic_forcasting(\n",
    "    dataset_preprocessed: Input[Dataset],\n",
    "    dataset_site_preprocessed: Input[Dataset],\n",
    "    df_traffic_predicted: Output[Dataset]\n",
    "    \n",
    "\n",
    "):\n",
    "    import pandas as pd\n",
    "    import pandas_gbq\n",
    "    from src.d03_capacity.technical_modules.traffic_forecasting import prophet\n",
    "    \n",
    "    traffic_preprocessed = pd.read_csv(dataset_preprocessed.path)\n",
    "    site_preprocessed = pd.read_csv(dataset_site_preprocessed.path)\n",
    "    \n",
    "    traffic_predicted = prophet(traffic_preprocessed)\n",
    "    \n",
    "    traffic_predicted.drop('site_id', axis=1, inplace=True)\n",
    "    traffic_predicted = traffic_predicted.merge(site_preprocessed[['site_id', 'cell_name']].drop_duplicates(),\n",
    "                                                      how='left',\n",
    "                                                      on='cell_name')\n",
    "    traffic_predicted.dropna(subset=['site_id'], inplace=True)\n",
    "    \n",
    "    traffic_predicted.to_csv(df_traffic_predicted.path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aaa8b02-8c27-4083-9b20-fd61cd04099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    output_component_file=\"components/upgrade_selection.yaml\"\n",
    ")\n",
    "\n",
    "def process_bands_to_upgrade(\n",
    "    dataset_distance: Input[Dataset],\n",
    "    df_traffic_predicted: Input[Dataset],\n",
    "    dataset_site_preprocessed: Input[Dataset],\n",
    "    dataset_typology_sector: Input[Dataset],\n",
    "    dataset_selected_band_per_site : Output[Dataset],\n",
    "    dataset_affected_cells: Output[Dataset],\n",
    "    dataset_cluster_future_upgrades: Output[Dataset]\n",
    "    \n",
    "    \n",
    "    \n",
    "):\n",
    "    import pandas as pd\n",
    "    import pandas_gbq\n",
    "    from src.d03_capacity.technical_modules.upgrade_selection import upgrade_selection_pipeline\n",
    "    from src.d03_capacity.technical_modules.cluster_selection import get_cluster_of_future_upgrades\n",
    "    from src.d00_conf.conf import conf, conf_loader\n",
    "    \n",
    "    conf_loader(\"OSN\")\n",
    "\n",
    "    \n",
    "    df_predicted_traffic_kpis = pd.read_csv(df_traffic_predicted.path)\n",
    "    df_sites = pd.read_csv(dataset_site_preprocessed.path)\n",
    "    df_typology_sector = pd.read_csv(dataset_typology_sector.path)\n",
    "    df_distance = pd.read_csv(dataset_distance.path)\n",
    "    print(\"Process bands to upgrade\")\n",
    "    \n",
    "    selected_band_per_site = upgrade_selection_pipeline(df_predicted_traffic_kpis.copy(),df_typology_sector,df_sites)\n",
    "    \n",
    "    df_affected_cells = df_predicted_traffic_kpis.merge(selected_band_per_site,\n",
    "                                                              on='site_id',\n",
    "                                                              how='inner')\n",
    "    \n",
    "    df_cluster_future_upgrades = get_cluster_of_future_upgrades(selected_band_per_site,\n",
    "                                                                df_distance,\n",
    "                                                                max_neighbors=conf['TRAFFIC_IMPROVEMENT'][\n",
    "                                                                    'MAX_NUMBER_OF_NEIGHBORS'])\n",
    "    \n",
    "    selected_band_per_site.to_csv(dataset_selected_band_per_site.path, index=False)\n",
    "    df_affected_cells.to_csv(dataset_affected_cells.path, index=False)\n",
    "    df_cluster_future_upgrades.to_csv(dataset_cluster_future_upgrades.path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4730c923-80c4-4bf2-a9ac-d4c4f532e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE,\n",
    "    output_component_file=\"components/train_technical_pipeline.yaml\"\n",
    ")\n",
    "def train_technical_pipeline (\n",
    "    dataset_oss_preprocessed: Input[Dataset],\n",
    "    dataset_site_preprocessed: Input[Dataset],\n",
    "    dataset_distance: Input[Dataset],\n",
    "    dataset_cell_affected: Output[Dataset],\n",
    "    dataset_list_of_upgrades: Output[Dataset],\n",
    "    data_traffic_features: Output[Dataset],\n",
    "    voice_traffic_features: Output[Dataset],\n",
    "):\n",
    "    import pandas as pd\n",
    "    from src.d03_capacity.technical_modules.activation_model import get_affected_cells_with_interactions_between_upgrades\n",
    "    from src.d03_capacity.technical_modules.cluster_selection import get_cluster_of_affected_sites\n",
    "    from src.d03_capacity.technical_modules.traffic_improvement import get_all_traffic_improvement_features,compute_traffic_after\n",
    "    from src.d00_conf.conf import conf, conf_loader\n",
    "\n",
    "    conf_loader(\"OSN\")\n",
    "\n",
    "    df_traffic_weekly_kpis = pd.read_csv(dataset_oss_preprocessed.path)\n",
    "    df_sites = pd.read_csv(dataset_site_preprocessed.path)\n",
    "    df_distance = pd.read_csv(dataset_distance.path)\n",
    "\n",
    "    print(\"train_technical_pipeline\")\n",
    "    if conf['COUNTRY']=='OSN':\n",
    "        df_traffic_weekly_kpis = df_traffic_weekly_kpis.replace({'cell_band': {'F2_U2100': 'U2100', 'F3_U2100': 'U2100', 'F1_U900': 'U900',\n",
    "                                                                           'F1_U2100':'U2100','F4_U2100':'U2100','F2_U900':'U900'}})\n",
    "\n",
    "\n",
    "    print(\"enter get_affected_cells_with_interactions_between_upgrades\")\n",
    "    df_cell_affected = get_affected_cells_with_interactions_between_upgrades(df_traffic_weekly_kpis)\n",
    "\n",
    "    list_of_upgrades, sites_to_remove = get_cluster_of_affected_sites(df_cell_affected,\n",
    "                                                                      df_distance)\n",
    "\n",
    "    df_cell_affected.to_csv(dataset_cell_affected.path, index=False)\n",
    "    list_of_upgrades.to_csv(dataset_list_of_upgrades.path, index=False)\n",
    "    \n",
    "    \n",
    "    print(\"Process features to train traffic improvement and traffic trend models\")\n",
    "    df_data_traffic_features = get_all_traffic_improvement_features(df_traffic_weekly_kpis,\n",
    "                                                                       df_cell_affected,\n",
    "                                                                       list_of_upgrades,\n",
    "                                                                       sites_to_remove,\n",
    "                                                                       df_sites,\n",
    "                                                                       type_of_traffic='data',\n",
    "                                                                       group_bands=False,\n",
    "                                                                       remove_sites_with_more_than_one_upgrade_same_cluster=True,\n",
    "                                                                       kpi_to_compute_upgrade_effect=[\n",
    "                                                                           \"total_data_traffic_dl_gb\"],\n",
    "                                                                       capacity_kpis_features=[\n",
    "                                                                           \"cell_occupation_dl_percentage\"],\n",
    "                                                                       upgraded_to_not_consider=[])\n",
    "    \n",
    "    df_data_traffic_features = compute_traffic_after(df_data_traffic_features,df_traffic_weekly_kpis,'total_data_traffic_dl_gb')\n",
    "    \n",
    "    df_voix_traffic_features = get_all_traffic_improvement_features(df_traffic_weekly_kpis,\n",
    "                                                                       df_cell_affected,\n",
    "                                                                       list_of_upgrades,\n",
    "                                                                       sites_to_remove,\n",
    "                                                                       type_of_traffic='voice',\n",
    "                                                                       group_bands=False,\n",
    "                                                                       remove_sites_with_more_than_one_upgrade_same_cluster=True,\n",
    "                                                                       kpi_to_compute_upgrade_effect=[\n",
    "                                                                           \"total_voice_traffic_kerlands\"],\n",
    "                                                                       capacity_kpis_features=[\n",
    "                                                                           \"cell_occupation_dl_percentage\"],\n",
    "                                                                       upgraded_to_not_consider=[])\n",
    "    \n",
    "    df_voix_traffic_features = compute_traffic_after(df_voix_traffic_features,df_traffic_weekly_kpis,'total_voice_traffic_kerlands')\n",
    "    \n",
    "    \n",
    "    df_data_traffic_features.to_csv(data_traffic_features.path, index=False)\n",
    "    df_voice_traffic_features.to_csv(voice_traffic_features.path, index=False)\n",
    "    \n",
    "    \n",
    "    print(\"Train traffic improvement and traffic trend models\")\n",
    "    \n",
    "#     train_traffic_improvement_model(df_data_traffic_features,\n",
    "#                                                            type_of_traffic='data',\n",
    "#                                                            remove_samples_with_target_variable_lower=True,\n",
    "#                                                            output_route=conf['PATH']['MODELS'],\n",
    "#                                                            results_route=conf['PATH']['MODELS_OUTPUT'],\n",
    "#                                                            bands_to_consider=['G900', 'G1800','L2600', 'L1800', 'L800', 'U2100',\n",
    "#                                                                               'U900'],\n",
    "#                                                            save_model=True)\n",
    "    \n",
    "#     train_traffic_improvement_model(df_voice_traffic_features,\n",
    "#                                                            type_of_traffic='voice',\n",
    "#                                                            remove_samples_with_target_variable_lower=True,\n",
    "#                                                            output_route=conf['PATH']['MODELS'],\n",
    "#                                                            results_route=conf['PATH']['MODELS_OUTPUT'],\n",
    "#                                                            bands_to_consider=['G900', 'G1800','L2600','L1800', 'L800', 'U2100',\n",
    "#                                                                               'U900'],\n",
    "#                                                            save_model=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92914fae-62c7-49e6-b6f2-93c75f0fa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE TIMESTAMP TO DEFINE UNIQUE PIPELINE NAMES\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "DISPLAY_NAME = 'pipeline-smartcapex-job{}'.format(TIMESTAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c774744-6394-4102-9716-ea7d380841db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline. Use to determine the pipeline Context.\n",
    "    name=\"smartcapex-pipeline\"   \n",
    ")\n",
    "\n",
    "def pipeline(\n",
    "     \n",
    "    dataset_src: str,\n",
    "    table_site_raw: str,   \n",
    "    table_oss_2g_raw: str, \n",
    "    table_oss_3g_raw: str, \n",
    "    table_oss_4g_raw: str, \n",
    "    table_oss_rtx_raw: str,\n",
    "    table_typology_sector_raw: str,\n",
    "    dataset_preprocessing: str,\n",
    "    df_sites: str,\n",
    "    oss_counter_weekly: str,\n",
    "    dataset_intermediate : str,\n",
    "    df_traffic_predicted :str,\n",
    "    df_distance :str,\n",
    "    df_selected_band_per_site :str,\n",
    "    df_affected_cells :str,\n",
    "    df_future_upgrades :str,\n",
    "    project: str = PROJECT_ID,\n",
    "):\n",
    "\n",
    "    get_data_sites_op = get_data(project,dataset_src,table_site_raw)\n",
    "    get_data_oss_2g_op = get_data(project,dataset_src,table_oss_2g_raw)\n",
    "    get_data_oss_3g_op = get_data(project,dataset_src,table_oss_3g_raw)\n",
    "    get_data_oss_4g_op = get_data(project,dataset_src,table_oss_4g_raw)\n",
    "    get_data_oss_rtx_op = get_data(project,dataset_src,table_oss_rtx_raw)\n",
    "    \n",
    "    data_preprocess_op = preprocess_data(get_data_sites_op.outputs[\"dataset_raw\"],get_data_oss_2g_op.outputs[\"dataset_raw\"],get_data_oss_3g_op.outputs[\"dataset_raw\"],\\\n",
    "                                         get_data_oss_4g_op.outputs[\"dataset_raw\"],get_data_oss_rtx_op.outputs[\"dataset_raw\"])\n",
    "    \n",
    "    save_to_bigquery_sites_op = save_to_bigquery(data_preprocess_op.outputs[\"dataset_sites_preprocessed\"],project,dataset_preprocessing,df_sites)\n",
    "    save_to_bigquery_oss_op = save_to_bigquery(data_preprocess_op.outputs[\"dataset_oss_preprocessed\"],project,dataset_preprocessing,oss_counter_weekly)\n",
    "    \n",
    "    traffic_forcasting_op = (traffic_forcasting(data_preprocess_op.outputs[\"dataset_oss_preprocessed\"],data_preprocess_op.outputs[\"dataset_sites_preprocessed\"])).set_cpu_limit('16').set_memory_limit('60G')\n",
    "    save_to_bigquery_traffic_predicted_op = save_to_bigquery(traffic_forcasting_op.outputs[\"df_traffic_predicted\"],project,dataset_intermediate,df_traffic_predicted)\n",
    "    \n",
    "    compute_sites_distances_op = compute_sites_distances(data_preprocess_op.outputs[\"dataset_sites_preprocessed\"])\n",
    "    save_to_bigquery_sites_distances_op = save_to_bigquery(compute_sites_distances_op.outputs[\"df_distance\"],project,dataset_intermediate,df_distance)\n",
    "\n",
    "    get_data_typology_op = get_data(project,dataset_src,table_typology_sector_raw)\n",
    "    upgrade_selection_op = process_bands_to_upgrade(compute_sites_distances_op.outputs[\"df_distance\"],traffic_forcasting_op.outputs[\"df_traffic_predicted\"],data_preprocess_op.outputs[\"dataset_sites_preprocessed\"],get_data_typology_op.outputs[\"dataset_raw\"])\n",
    "    \n",
    "    save_to_bigquery_selected_band_per_site_op = save_to_bigquery(upgrade_selection_op.outputs[\"dataset_selected_band_per_site\"],project,dataset_intermediate,df_selected_band_per_site)\n",
    "    save_to_bigquery_affected_cells_op = save_to_bigquery(upgrade_selection_op.outputs[\"dataset_affected_cells\"],project,dataset_intermediate,df_affected_cells)\n",
    "    save_to_bigquery_future_upgrades_op = save_to_bigquery(upgrade_selection_op.outputs[\"dataset_cluster_future_upgrades\"],project,dataset_intermediate,df_future_upgrades)\n",
    "    \n",
    "    train_technical_pipeline_op = train_technical_pipeline(data_preprocess_op.outputs[\"dataset_oss_preprocessed\"],data_preprocess_op.outputs[\"dataset_sites_preprocessed\"],compute_sites_distances_op.outputs[\"df_distance\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59707ada-8d6d-40f2-a2aa-b1160b4547ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1293: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline,\n",
    "        package_path='components/smartcapex-pipeline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d431f8e-59e8-4e49-aa51-916308a868b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pipeline = pipeline_jobs.PipelineJob(\n",
    "    display_name=\"smartcapex-pipeline\",\n",
    "    template_path=\"components/smartcapex-pipeline.json\",\n",
    "    parameter_values={\n",
    "        \"project\": \"osn-smartcapex-404-sbx\",\n",
    "        \"dataset_src\": \"Dataset_SmartCapex\",\n",
    "        \"table_site_raw\": \"Thies_referentielSite-OCI\",   \n",
    "        \"table_oss_2g_raw\": \"osscounter2G-OCI\", \n",
    "        \"table_oss_3g_raw\": \"osscounter3G-OCI\", \n",
    "        \"table_oss_4g_raw\": \"osscounter4G-OCI\", \n",
    "        \"table_oss_rtx_raw\": \"trx2G-OCI\",\n",
    "        \"table_typology_sector_raw\": \"typology_sector\",\n",
    "        \"dataset_preprocessing\": \"preprocessing\",\n",
    "        \"df_sites\": \"df_sites\",\n",
    "        \"oss_counter_weekly\": \"oss_counter_weekly\",\n",
    "        \"dataset_intermediate\": \"intermediate\",\n",
    "        \"df_traffic_predicted\":\"df_predicted_traffic_kpis\",\n",
    "        \"df_distance\": \"df_distance\",\n",
    "        \"df_selected_band_per_site\" :\"df_selected_band_per_site_upgrade_selection\" ,\n",
    "        \"df_affected_cells\" :\"df_affected_cells_upgrade_selection\",\n",
    "        \"df_future_upgrades\" :\"df_future_upgrades_upgrade_selection\",\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98a9358-c0e2-4815-b2e5-46ad63204712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/989544951348/locations/europe-west1/pipelineJobs/smartcapex-pipeline-20230712151832\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/989544951348/locations/europe-west1/pipelineJobs/smartcapex-pipeline-20230712151832')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west1/pipelines/runs/smartcapex-pipeline-20230712151832?project=989544951348\n",
      "PipelineJob projects/989544951348/locations/europe-west1/pipelineJobs/smartcapex-pipeline-20230712151832 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/989544951348/locations/europe-west1/pipelineJobs/smartcapex-pipeline-20230712151832 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/989544951348/locations/europe-west1/pipelineJobs/smartcapex-pipeline-20230712151832 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/989544951348/locations/europe-west1/pipelineJobs/smartcapex-pipeline-20230712151832 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [train-technical-pipeline].; Job (project_id = osn-smartcapex-404-sbx, job_id = 7162106593146830848) is failed due to the above error.; Failed to handle the job: {project_number = 989544951348, job_id = 7162106593146830848}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_14745/1043187068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    349\u001b[0m         )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     def submit(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [train-technical-pipeline].; Job (project_id = osn-smartcapex-404-sbx, job_id = 7162106593146830848) is failed due to the above error.; Failed to handle the job: {project_number = 989544951348, job_id = 7162106593146830848}\"\n"
     ]
    }
   ],
   "source": [
    "start_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d6d2b-5257-4013-8473-a9456bbf956f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6083277-19fa-4f78-9a45-9842cc161a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d8ba7-5354-4a77-babb-a9abb53d904d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d041e-91ce-41bc-833f-44dd1c8820cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e65cd4-721c-48db-b2ae-c0fd8bb4f708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31c319-1951-42f4-a494-ca32360c6c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0877b6e-8041-4f30-8cc3-2413f812f2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53607425-1a1e-4069-898b-4d3d0619c387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
